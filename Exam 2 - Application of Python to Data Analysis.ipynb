{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><font color=\"red\">**DO NOT DISTRIBUTE**</font></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This exam will assess your ability to use Python for data preparation, visualization, and prediction. At a minimum, you must provide what is ask at each step - but you may include additional analysis if you deem it appropriate. \n",
    "\n",
    "**Do not include more than one idea per notebook cell.** Practically, this means that each cell should contain only a single function definition or a single statement. The obvious exception to this is a block of human-readable text to explain what you are doing, or what your output means. Violation of this principle will result in **5%** being deducted from your final grade. Presentation of analysis and results is almost as important as their accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1 - Regression\n",
    "\n",
    "Explore the Auto-Mpg Dataset and use your findings to develop a model that will accurately predict the miles-per-gallon of a car based on one or more factors. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the Necessary Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the Data\n",
    "\n",
    "Create a function that will read in the Auto-Mpg dataset using the standard python libraries and store the data in a Pandas `DataFrame` object. \n",
    "- The dataset can be found in the webcourse site's \"Files\" section, under the \"Exams\" folder. \n",
    "- Your function should take the file path to the data set as a parameter and return the `DataFrame` object that it creates. \n",
    "- Only store the brand of the car, not the full name (e.g. \"chevrolet\" instead of \"chevrolet chevelle malibu\")\n",
    "\n",
    "An example use of this function would resemble:\n",
    "\n",
    "`mpg_df = load_dataset(\"auto-mpg.data\")`\n",
    "\n",
    "You are not to use pandas or numpy to read in the actual file. Your code should use `open()` inside of a context manager. If you use an existing library to open and parse the data file (e.g. pandas, numpy, csv), you will only receive 50% credit for Problem 1.\n",
    "\n",
    "**HINT -** Recall that a data frame can be created from a list of dictionaries. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use your function to read in the the Auto-Mpg dataset and then use the `info()` function to make sure that the structure looks correct. The structure should follow:\n",
    "\n",
    "<pre>\n",
    "1. Number of Instances: 398\n",
    "\n",
    "2. Number of Attributes: 9 including the class attribute\n",
    "\n",
    "3. Attribute Information:\n",
    "\n",
    "    1. mpg:           continuous\n",
    "    2. cylinders:     multi-valued discrete\n",
    "    3. displacement:  continuous\n",
    "    4. horsepower:    continuous\n",
    "    5. weight:        continuous\n",
    "    6. acceleration:  continuous\n",
    "    7. model year:    multi-valued discrete\n",
    "    8. origin:        multi-valued discrete\n",
    "    9. car brand:      string (unique for each instance)\n",
    "</pre>\n",
    "\n",
    "If the data you have read in does not conform the expected structure, fix it. This may include renaming columns and converting the data type of one or more columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the Data (5 points)\n",
    "\n",
    "Now that you have stored your data in a `DataFrame` object and corrected its structure, you will examine the data to check for:\n",
    "\n",
    "- missing data\n",
    "- outliers\n",
    "- anomalies\n",
    "\n",
    "If any of these data problems occur, print out the rows with the problem before you modify the data frame. Use your best judgement when it comes to resolving these issues.\n",
    "\n",
    "**HINT** - Sometimes it is easier to visualize the data to get an idea of problem entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Data\n",
    "\n",
    "Now that you have cleaned the data, you will explore it and try to identify the features that may be important in predicting `mpg` data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a histogram for each variable in the dataset (8 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create scatter plots of mpg vs. every other variable in the dataset. (e.g. weight vs. mpg, origin vs. mpg). Color your data based on the brand of the car (7 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate the pearson correlation between `mpg` and the other variables. (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Which variables appear to be correlated to `mpg`? (1 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Is there multicollinearity within the data? (1 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Predictive Model of MPG\n",
    "\n",
    "#### Divide your data into a training set and a test set. Use 30% of the data for your test set (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**WARNING** - The following substeps may take substantial computational time, depending on your computer hardware. If you lack the computing power to use GridSearchCV, you may use RandomizedSearchCV instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Regression (6 points)\n",
    "\n",
    "Using the training data:\n",
    "- Build a pipeline that fits scaled data to a polynomial LASSO regression model\n",
    "  - Use GridSearchCV to identify the best hyperparameters\n",
    "    - It is up to you to select sufficient and appropriate ranges for PolynomialFeatures.degree and Lasso.alpha\n",
    "  - Display the best parameters\n",
    "  - Display the score\n",
    "\n",
    "**HINT** You will need to make a pipeline from a StandardScaler(), PolynomialFeatures(), and Lasso() object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression (6 points)\n",
    "\n",
    "Using the training data:\n",
    "- Build a pipeline that fits scaled data to a polynomial Ridge regression model\n",
    "  - Use GridSearchCV to identify the best hyperparameters\n",
    "    - It is up to you to select sufficient and appropriate ranges PolynomialFeatures.degree and Ridge.alpha\n",
    "  - Display the best parameters\n",
    "  - Display the score\n",
    "\n",
    "**HINT** You will need to make a pipeline from a StandardScaler(), PolynomialFeatures(), and Ridge() object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Regression with PCA (6 points)\n",
    "\n",
    "Using the training data:\n",
    "- Build a pipeline that performs PCA on scaled data and then fits the results to a polynomial Lasso regression model\n",
    "  - Use GridSearchCV to identify the best hyperparameters\n",
    "    - It is up to you to select sufficient and appropriate ranges for PCA.n_components, PolynomialFeatures.degree, and Lasso.alpha\n",
    "  - Display the best parameters\n",
    "  - Display the score\n",
    "\n",
    "**HINT -** You will need to make a pipeline from a StandardScaler(), PCA(), PolynomialFeatures(), and Lasso() object.\n",
    "\n",
    "**HINT -** You may need to construct Lasso with `max_iter=10000` if your alpha values are small and you get convergence warnings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression with PCA (6 points)\n",
    "\n",
    "Using the training data:\n",
    "- Build a pipeline that performs PCA on scaled data and then fits the results to a polynomial Ridge regression model\n",
    "  - Use GridSearchCV to identify the best hyperparameters\n",
    "    - It is up to you to select sufficient and appropriate ranges for PCA.n_components, PolynomialFeatures.degree, and Ridge.alpha\n",
    "  - Display the best parameters\n",
    "  - Display the score\n",
    "\n",
    "**HINT -** You will need to make a pipeline from a StandardScaler(), PCA(), PolynomialFeatures(), and Ridge() object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare the score of each model and identify which model does best on the training data (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All four models are close, but it looks like transforming the data with PCA and removing some components may do better on the training set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Validate the Model (1 point)\n",
    "\n",
    "Using your test data constructed in Step 4, validate your models and identify which one has the highest score for predicting `mpg`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw Your Conclusions (5 points)\n",
    "\n",
    "Which model does best, and why do you think that is the case? Are there alternative models that might do better?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2 (3 point)\n",
    "\n",
    "Compare and contrast SAS and Python for use in Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3 (1 point)\n",
    "\n",
    "What did you like most about this course?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 4 (1 point)\n",
    "\n",
    "What did you like least about this course?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 5 - Classification (Bonus Problem - 20%)\n",
    "\n",
    "*This problem is not required, but you can earn 4% extra on this exam for reading in and cleaning the data, and then 4% extra for each classifier that you implement (for a total of 20% extra to your grade - 14 points).*  \n",
    "\n",
    "Download the iris dataset from the Exam folder within the webcourse Files section and then analyze the iris dataset and build the following classifiers:\n",
    "- SVC\n",
    "- NearestNeighbors\n",
    "- KMeans\n",
    "- RandomForestClassifier\n",
    "\n",
    "For each classifier, fit it to a training set, show how well it does on that training set, and then score it on a test set. Use data transformers and GridSearchCV as necessary.\n",
    "\n",
    "The general structure of your solution should follow Problem 1. Credit will be assigned all or nothing on a per-classifier basis - there is no partial credit for this problem."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
